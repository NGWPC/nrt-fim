{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from rasterio import features\n",
    "from rasterio.enums import Resampling\n",
    "from shapely.geometry import mapping\n",
    "from tqdm import trange\n",
    "\n",
    "import trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in NWM retrospective data and define the HUC8 bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.strptime(\"20190524 120000\", \"%Y%m%d %H%M%S\")\n",
    "end_time = datetime.strptime(\"20190527 120000\", \"%Y%m%d %H%M%S\")\n",
    "ds_r, ds_sm = trainer.read(start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"../data/boundaries/11070103_huc.gpkg\")\n",
    "bounds = gdf.total_bounds\n",
    "minx, miny, maxx, maxy = bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the bounding box around the HUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "\n",
    "bbox = box(*bounds)\n",
    "\n",
    "# If you want to plot the bounding box along with your HUC8 shape\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "gdf.plot(ax=ax)\n",
    "bbox_gdf = gpd.GeoDataFrame(geometry=[bbox], crs=gdf.crs)\n",
    "bbox_gdf.plot(ax=ax, color=\"none\", edgecolor=\"red\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the observation data, and clip it to the bounding box "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster = rioxarray.open_rasterio(\"../data/sentinel/cloud_cutout_extent_filled_optimized.tif\")\n",
    "raster_5070 = raster.rio.reproject(\"EPSG:5070\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_raster = raster_5070.rio.clip_box(minx=minx, miny=miny, maxx=maxx, maxy=maxy)\n",
    "\n",
    "clipped_raster.rio.to_raster(\"../data/sentinel/cloud_cutout_extent_clipped_huc8.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors = [(1, 1, 1, 0), (0, 0, 0.5, 0.5), (0, 0, 1, 1)]  # Transparent to dark blue\n",
    "water_cmap = LinearSegmentedColormap.from_list(\"water_cmap\", colors)\n",
    "im2 = clipped_raster.plot(ax=ax, cmap=water_cmap, vmin=0, vmax=1)\n",
    "ax.set_title(\"Raster with NoData filled as 0\")\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "gdf.boundary.plot(ax=ax, color=\"red\", linewidth=1)\n",
    "plt.title(\"Clipped Raster with HUC8 Boundary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample to 250m, and find the percent surface water in each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_flood_percentage(raster, target_resolution=250):\n",
    "    \"\"\"Calculates flood percentage and returns a raster\"\"\"\n",
    "    # Get the current resolution and dimensions\n",
    "    current_res_x, current_res_y = raster.rio.resolution()\n",
    "    current_width = raster.rio.width\n",
    "    current_height = raster.rio.height\n",
    "\n",
    "    # Calculate the scale factor\n",
    "    scale_x = abs(target_resolution / current_res_x)\n",
    "    scale_y = abs(target_resolution / current_res_y)\n",
    "\n",
    "    # Calculate new dimensions\n",
    "    new_width = int(current_width / scale_x)\n",
    "    new_height = int(current_height / scale_y)\n",
    "\n",
    "    # Create an empty array for our percentages\n",
    "    percentages = np.zeros((raster.rio.count, new_height, new_width))\n",
    "\n",
    "    # Get the data as a numpy array\n",
    "    data = raster.values\n",
    "\n",
    "    # For each band\n",
    "    for b in range(raster.rio.count):\n",
    "        # Get the band data\n",
    "        band_data = data[b]\n",
    "\n",
    "        # Identify pixels with value 1 (flooded)\n",
    "        binary_mask = (band_data == 1).astype(np.float32)\n",
    "\n",
    "        # Calculate percentage for each block\n",
    "        for i in range(new_height):\n",
    "            for j in range(new_width):\n",
    "                # Calculate corresponding indices in the original raster\n",
    "                start_y = int(i * scale_y)\n",
    "                end_y = int(min((i + 1) * scale_y, current_height))\n",
    "                start_x = int(j * scale_x)\n",
    "                end_x = int(min((j + 1) * scale_x, current_width))\n",
    "\n",
    "                # Extract the block from the original data\n",
    "                block = binary_mask[start_y:end_y, start_x:end_x]\n",
    "\n",
    "                # Calculate total number of valid pixels in the block\n",
    "                total_pixels = block.size\n",
    "\n",
    "                # Skip if no valid pixels (avoid division by zero)\n",
    "                if total_pixels == 0:\n",
    "                    percentages[b, i, j] = np.nan\n",
    "                    continue\n",
    "\n",
    "                # Calculate percentage of flooded pixels\n",
    "                flood_count = np.sum(block)\n",
    "                percentages[b, i, j] = (flood_count / total_pixels) * 100\n",
    "\n",
    "    # Create a new raster with the percentages\n",
    "    percentage_raster = raster.rio.reproject(\n",
    "        raster.rio.crs, shape=(new_height, new_width), resampling=Resampling.nearest\n",
    "    )\n",
    "\n",
    "    # Replace the values with our percentages\n",
    "    percentage_raster.values = percentages\n",
    "\n",
    "    return percentage_raster\n",
    "\n",
    "\n",
    "target_resolution = 250\n",
    "# Apply the function to your reprojected raster\n",
    "flood_percent_250m = calculate_flood_percentage(clipped_raster, target_resolution=target_resolution)\n",
    "\n",
    "# Save the percentage raster\n",
    "# flood_percent_250m.rio.to_raster(\"../data/sentinel/flood_percent_250m.tif\")\n",
    "\n",
    "# Print some statistics\n",
    "total_flooded_pixels_original = (clipped_raster.values == 1).sum()\n",
    "\n",
    "# Calculate the equivalent number of original pixels from the percentage data\n",
    "# Each target pixel represents (scale_x * scale_y) original pixels\n",
    "current_res_x, current_res_y = clipped_raster.rio.resolution()\n",
    "scale_x = abs(target_resolution / current_res_x)\n",
    "scale_y = abs(target_resolution / current_res_y)\n",
    "pixels_per_target = scale_x * scale_y\n",
    "\n",
    "# For each target pixel, its percentage tells us how many original pixels were flooded\n",
    "# Sum up (percentage/100 * pixels_per_target) for all target pixels\n",
    "equivalent_flooded_pixels = np.nansum(flood_percent_250m.values / 100 * pixels_per_target)\n",
    "\n",
    "print(f\"Total flooded pixels in original: {total_flooded_pixels_original}\")\n",
    "print(f\"Equivalent flooded pixels from percentage raster: {equivalent_flooded_pixels:.1f}\")\n",
    "print(f\"Difference: {equivalent_flooded_pixels - total_flooded_pixels_original:.1f} pixels\")\n",
    "print(\n",
    "    f\"Percentage difference: {((equivalent_flooded_pixels - total_flooded_pixels_original) / total_flooded_pixels_original) * 100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "im2 = flood_percent_250m.plot(ax=ax)\n",
    "ax.set_title(\"Raster with NoData filled as 0\")\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "gdf.boundary.plot(ax=ax, color=\"red\", linewidth=1)\n",
    "plt.title(\"Clipped Raster with HUC8 Boundary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create inputs from NWM retrospective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhd_gpd = gpd.read_file(\"../data/boundaries/nwm_catchments_original.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_polygon = box(*bounds)\n",
    "polygon_path = Path(\"../data/sample_dir/polygons_nhd.gpkg\")\n",
    "if polygon_path.exists():\n",
    "    combined_polys = gpd.read_file(polygon_path)\n",
    "else:\n",
    "    # Create a GeoDataFrame from the bounding box\n",
    "    bbox_gdf = gpd.GeoDataFrame(geometry=[bbox_polygon], crs=gdf.crs)\n",
    "\n",
    "    # Ensure both datasets are in the same CRS\n",
    "    if nhd_gpd.crs != bbox_gdf.crs:\n",
    "        nhd_gpd = nhd_gpd.to_crs(bbox_gdf.crs)\n",
    "\n",
    "    # # Find polygons that are fully within the bounding box\n",
    "    # within_polys = nhd_gpd[nhd_gpd.within(bbox_polygon)]\n",
    "\n",
    "    # # Find polygons that intersect with the bounding box but aren't fully within it\n",
    "    # intersecting_polys = nhd_gpd[nhd_gpd.intersects(bbox_polygon) & ~nhd_gpd.within(bbox_polygon)]\n",
    "\n",
    "    # Combined result: all polygons that are either within or intersect the bbox\n",
    "    combined_polys = nhd_gpd[nhd_gpd.intersects(bbox_polygon)]\n",
    "    combined_polys.to_file(polygon_path, driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dynamic inputs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_sm.rio.write_crs(ds_sm.attrs[\"esri_pe_string\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = rioxarray.open_rasterio(\n",
    "    Path(\"/Users/taddbindas/projects/NGWPC/f1_trainer/data/sample_dir/flood_percent_250m.tif\"),\n",
    "    chunked_array_type=\"cubed\",\n",
    ")\n",
    "template_grid = obs.isel(band=0) if \"band\" in obs.dims else obs\n",
    "grid_crs = template_grid.rio.crs\n",
    "grid_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_crs = template_grid.rio.crs\n",
    "obs_transform = template_grid.rio.transform()\n",
    "obs_width = template_grid.x.size\n",
    "obs_height = template_grid.y.size\n",
    "obs_bounds = template_grid.rio.bounds()\n",
    "\n",
    "# Get the source data\n",
    "_ds = ds.isel(soil_layers_stag=0)\n",
    "\n",
    "arr = []\n",
    "for i in trange(_ds.time.shape[0]):\n",
    "    # Get time slice of soil moisture\n",
    "    time_slice = _ds.isel(time=i)\n",
    "\n",
    "    # Reproject directly to match observation grid in one step\n",
    "    sm_reprojected = time_slice.rio.reproject(\n",
    "        grid_crs, shape=(obs_height, obs_width), transform=obs_transform, resampling=Resampling.bilinear\n",
    "    )\n",
    "\n",
    "    # Ensure the coordinates match exactly (important!)\n",
    "    sm_aligned = sm_reprojected.assign_coords(\n",
    "        {\"x\": template_grid.x, \"y\": template_grid.y, \"spatial_ref\": template_grid.spatial_ref}\n",
    "    )\n",
    "\n",
    "    # Add to our array of time slices\n",
    "    arr.append(sm_aligned)\n",
    "\n",
    "# Combine all time slices\n",
    "soil_moisture_aligned = xr.concat(arr, dim=\"time\")\n",
    "soil_moisture_aligned = soil_moisture_aligned.assign_coords(time=_ds.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot the filled raster\n",
    "im2 = soil_moisture_aligned.isel(time=-1).plot(ax=ax)\n",
    "ax.set_title(\"Raster with NoData filled as 0\")\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "gdf.boundary.plot(ax=ax, color=\"red\", linewidth=1)\n",
    "plt.title(\"Clipped Raster with HUC8 Boundary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# start_time = clipped_merge.time.values[0]\n",
    "# end_time = clipped_merge.time.values[-1]\n",
    "\n",
    "# Create hourly time range\n",
    "hourly_times = pd.date_range(start=start_time, end=end_time, freq=\"1H\")\n",
    "\n",
    "# Create the target dataset with the new time coordinates\n",
    "target = xr.Dataset(coords={\"time\": hourly_times})\n",
    "\n",
    "# Perform nearest neighbor interpolation\n",
    "clipped_merge_hourly = soil_moisture_aligned.interp(time=hourly_times, method=\"nearest\")\n",
    "# clipped_merge_hourly = clipped_merge_hourly.rio.write_crs(ds_sm.attrs[\"esri_pe_string\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_merge_hourly.rio.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_merge_hourly = clipped_merge_hourly.rio.write_crs(template_grid.rio.crs, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_polys = combined_polys.sort_values(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.isin(ds_r.feature_id.values, combined_polys[\"ID\"].values)\n",
    "matching_indices = np.where(mask)[0]\n",
    "clipped_ds_r = ds_r.isel(feature_id=matching_indices)\n",
    "# clipped_ds_r.isel(time=0)\n",
    "clipped_ds_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure polygons are in the same CRS as observations\n",
    "if grid_crs is not None and combined_polys.crs != grid_crs:\n",
    "    combined_polys_grid = combined_polys.to_crs(grid_crs)\n",
    "else:\n",
    "    combined_polys_grid = combined_polys\n",
    "\n",
    "arr = []\n",
    "for i in trange(clipped_ds_r.shape[0]):\n",
    "    feature_ids = clipped_ds_r.feature_id.values\n",
    "    runoff_values = clipped_ds_r.isel(time=i).values\n",
    "\n",
    "    # Create a dictionary mapping ID -> runoff value\n",
    "    runoff_map = dict(zip(feature_ids, runoff_values, strict=False))\n",
    "\n",
    "    # Apply the mapping to your polygons DataFrame\n",
    "    combined_polys_grid[\"runoff\"] = combined_polys_grid[\"ID\"].map(runoff_map)\n",
    "\n",
    "    # Create shapes and values for rasterio.features.rasterize\n",
    "    shapes = [\n",
    "        (mapping(geom), value)\n",
    "        for geom, value in zip(combined_polys_grid.geometry, combined_polys_grid[\"runoff\"], strict=False)\n",
    "    ]\n",
    "\n",
    "    # Get exact dimensions and transform from observation grid\n",
    "    out_shape = (template_grid.y.size, template_grid.x.size)\n",
    "    transform = template_grid.rio.transform()\n",
    "\n",
    "    # Rasterize the polygons directly to match observation grid\n",
    "    rasterized = features.rasterize(\n",
    "        shapes=shapes, out_shape=out_shape, transform=transform, fill=0, dtype=float, all_touched=False\n",
    "    )\n",
    "\n",
    "    # Convert to xarray with the same coordinates as the observation template\n",
    "    rasterized_xr = xr.DataArray(\n",
    "        data=rasterized,\n",
    "        dims=(\"y\", \"x\"),  # Ensure dimensions match observation grid\n",
    "        coords={\"y\": template_grid.y, \"x\": template_grid.x, \"spatial_ref\": template_grid.spatial_ref},\n",
    "        name=\"runoff\",\n",
    "        attrs={\"long_name\": \"Rasterized runoff from polygons\", \"units\": \"m3/s\"},\n",
    "    )\n",
    "    arr.append(rasterized_xr)\n",
    "\n",
    "# Create a Dataset instead of a DataArray to make it easier to work with\n",
    "runoff_time_coords = clipped_ds_r.time\n",
    "runoff_merge = xr.concat(arr, dim=\"time\")\n",
    "runoff_merge = runoff_merge.assign_coords(time=runoff_time_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Plot the filled raster\n",
    "im2 = runoff_merge.isel(time=65).plot(ax=ax)\n",
    "ax.set_title(\"Raster with NoData filled as 0\")\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "gdf.boundary.plot(ax=ax, color=\"red\", linewidth=1)\n",
    "plt.title(\"Clipped runoff with HUC8 Boundary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static attributes (flow accumulation, direction, surface water extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_acc = rioxarray.open_rasterio(\n",
    "    \"/Users/taddbindas/projects/NGWPC/f1_trainer/data/hydrosheds/hyd_na_acc_15s.tif\"\n",
    ")\n",
    "flow_dir = rioxarray.open_rasterio(\n",
    "    \"/Users/taddbindas/projects/NGWPC/f1_trainer/data/hydrosheds/hyd_na_dir_15s.tif\"\n",
    ")\n",
    "surface_extent = rioxarray.open_rasterio(\n",
    "    \"/Users/taddbindas/projects/NGWPC/f1_trainer/data/extents/extent_100W_40Nv1_4_2021.tif\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_acc_5070 = flow_acc.rio.reproject(\"EPSG:5070\")\n",
    "clipped_flow_acc = flow_acc_5070.rio.clip_box(minx=minx, miny=miny, maxx=maxx, maxy=maxy)\n",
    "flow_dir_5070 = flow_dir.rio.reproject(\"EPSG:5070\")\n",
    "clipped_flow_dir = flow_dir_5070.rio.clip_box(minx=minx, miny=miny, maxx=maxx, maxy=maxy)\n",
    "surface_extent_5070 = surface_extent.rio.reproject(\"EPSG:5070\")\n",
    "clipped_surface_extent = surface_extent_5070.rio.clip_box(minx=minx, miny=miny, maxx=maxx, maxy=maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_res_x, current_res_y = clipped_flow_acc.rio.resolution()\n",
    "scale_x = abs(250 / current_res_x)\n",
    "scale_y = abs(250 / current_res_y)\n",
    "new_width = int(clipped_flow_acc.rio.width / scale_x)\n",
    "new_height = int(clipped_flow_acc.rio.height / scale_y)\n",
    "\n",
    "clipped_flow_acc_250m = clipped_flow_acc.rio.reproject(\n",
    "    \"EPSG:5070\",\n",
    "    shape=(new_height, new_width),\n",
    "    resampling=Resampling.bilinear,  # Use bilinear for continuous data\n",
    ")\n",
    "\n",
    "current_res_x, current_res_y = clipped_flow_dir.rio.resolution()\n",
    "scale_x = abs(250 / current_res_x)\n",
    "scale_y = abs(250 / current_res_y)\n",
    "new_width = int(clipped_flow_dir.rio.width / scale_x)\n",
    "new_height = int(clipped_flow_dir.rio.height / scale_y)\n",
    "\n",
    "clipped_flow_dir_250m = clipped_flow_dir.rio.reproject(\n",
    "    \"EPSG:5070\",\n",
    "    shape=(new_height, new_width),\n",
    "    resampling=Resampling.bilinear,  # Use bilinear for continuous data\n",
    ")\n",
    "\n",
    "current_res_x, current_res_y = clipped_surface_extent.rio.resolution()\n",
    "scale_x = abs(250 / current_res_x)\n",
    "scale_y = abs(250 / current_res_y)\n",
    "new_width = int(clipped_surface_extent.rio.width / scale_x)\n",
    "new_height = int(clipped_surface_extent.rio.height / scale_y)\n",
    "\n",
    "clipped_surface_extent_250m = clipped_surface_extent.rio.reproject(\n",
    "    \"EPSG:5070\",\n",
    "    shape=(new_height, new_width),\n",
    "    resampling=Resampling.bilinear,  # Use bilinear for continuous data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# im2 = clipped_surface_extent_250m.plot(ax=ax)\n",
    "# ax.set_title(\"Flow dir raster\")\n",
    "# ax.set_xlabel(\"Longitude\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# gdf.boundary.plot(ax=ax, color='red', linewidth=1)\n",
    "# plt.title('Surface water extent with HUC8 Boundary')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_percent_250m.rio.to_raster(\"../data/sample_dir/flood_percent_250m.tif\")\n",
    "clipped_flow_acc_250m.rio.to_raster(\"../data/sample_dir/flow_acc_250m.tif\")\n",
    "clipped_flow_dir_250m.rio.to_raster(\"../data/sample_dir/flow_dir_250m.tif\")\n",
    "clipped_surface_extent_250m.rio.to_raster(\"../data/sample_dir/surface_extent_250m.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_path = Path(\"../data/sample_dir/soil_moisture.zarr\")\n",
    "r_path = Path(\"../data/sample_dir/router.zarr\")\n",
    "if not sm_path.exists():\n",
    "    clipped_merge_hourly.to_zarr(sm_path)\n",
    "if not r_path.exists():\n",
    "    runoff_merge.to_zarr(r_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
